{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Logical AND Function"
      ],
      "metadata": {
        "id": "CaOyyeOpS4Nu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTh2TKhtQV-u",
        "outputId": "b0eadf47-e399-4fc1-f8c9-93bd236251db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AND gate prediction:\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "[[0.00844026]\n",
            " [0.14993134]\n",
            " [0.15029998]\n",
            " [0.7856457 ]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "# Data for AND logic gate\n",
        "X_and = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y_and = np.array([[0], [0], [0], [1]])\n",
        "\n",
        "# Create and train the model\n",
        "model_and = Sequential()\n",
        "model_and.add(Dense(1, input_dim=2, activation='sigmoid'))\n",
        "model_and.compile(optimizer=SGD(learning_rate=0.1), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_and.fit(X_and, y_and, epochs=1000, verbose=0)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"AND gate prediction:\")\n",
        "print(model_and.predict(X_and))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logical OR Function\n"
      ],
      "metadata": {
        "id": "HO2Ta_3iS-nn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data for OR logic gate\n",
        "X_or = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y_or = np.array([[0], [1], [1], [1]])\n",
        "\n",
        "# Create and train the model\n",
        "model_or = Sequential()\n",
        "model_or.add(Dense(1, input_dim=2, activation='sigmoid'))\n",
        "model_or.compile(optimizer=SGD(learning_rate=0.1), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_or.fit(X_or, y_or, epochs=1000, verbose=0)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"OR gate prediction:\")\n",
        "print(model_or.predict(X_or))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvc27a4IShh0",
        "outputId": "4574188a-2af4-4ad6-8c37-bcfd7d84101b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OR gate prediction:\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "[[0.18280882]\n",
            " [0.9296089 ]\n",
            " [0.9283301 ]\n",
            " [0.99869394]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logical NOT Function"
      ],
      "metadata": {
        "id": "QpPXxhq7TDY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data for NOT logic gate\n",
        "X_not = np.array([[0], [1]])\n",
        "y_not = np.array([[1], [0]])\n",
        "\n",
        "# Create and train the model\n",
        "model_not = Sequential()\n",
        "model_not.add(Dense(1, input_dim=1, activation='sigmoid'))\n",
        "model_not.compile(optimizer=SGD(learning_rate=0.1), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_not.fit(X_not, y_not, epochs=1000, verbose=0)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"NOT gate prediction:\")\n",
        "print(model_not.predict(X_not))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2g6HQ7rzS0Jg",
        "outputId": "224c201b-dc62-400d-c8e4-b79cb2001f71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NOT gate prediction:\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "[[0.9351147 ]\n",
            " [0.04305496]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Logical XOR Function"
      ],
      "metadata": {
        "id": "yFIXdC2uUNTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data for XOR logic gate\n",
        "X_xor = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y_xor = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "# Create and train the model\n",
        "model_xor = Sequential()\n",
        "model_xor.add(Dense(2, input_dim=2, activation='relu'))\n",
        "model_xor.add(Dense(1, activation='sigmoid'))\n",
        "model_xor.compile(optimizer=SGD(learning_rate=0.1), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_xor.fit(X_xor, y_xor, epochs=1000, verbose=0)\n",
        "\n",
        "# Make predictions\n",
        "predict_xor = model_xor.predict(X_xor)\n",
        "print(\"XOR gate prediction:\")\n",
        "print(predict_xor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQvuMHkvTE7J",
        "outputId": "935d9f95-013b-46f3-ff40-a5ac21b00972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 50ms/step\n",
            "XOR gate prediction:\n",
            "[[0.6618109 ]\n",
            " [0.6618109 ]\n",
            " [0.6618109 ]\n",
            " [0.01306364]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Time Series Forecasting\n",
        "For the time series forecasting part, ensure the input shape is consistent."
      ],
      "metadata": {
        "id": "LA0KCPPmW9oZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Provided time series data\n",
        "data = np.array([0.68, 5.78, 0.25, 5.58, 1.31, 4.28, 1.57, 5.75, 0.41, 5.55, 0.90, 5.86, 0.03])\n",
        "data = data.reshape(-1, 1)\n",
        "\n",
        "# Scale the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "data = scaler.fit_transform(data)\n",
        "\n",
        "# Prepare the data for LSTM\n",
        "def create_dataset(data, look_back=1):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - look_back - 1):\n",
        "        X.append(data[i:(i + look_back), 0])\n",
        "        y.append(data[i + look_back:i + look_back + 2, 0])  # Adjusted to predict two symbols\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "look_back = 3\n",
        "X, y = create_dataset(data, look_back)\n",
        "\n",
        "# Reshape input to be [samples, time steps, features]\n",
        "X = np.reshape(X, (X.shape[0], look_back, 1))\n",
        "\n",
        "# Create and train the LSTM model\n",
        "model_lstm = Sequential()\n",
        "model_lstm.add(LSTM(50, input_shape=(look_back, 1)))\n",
        "model_lstm.add(Dense(2))  # Adjusted to predict two symbols\n",
        "model_lstm.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Train the model\n",
        "model_lstm.fit(X, y, epochs=50, batch_size=1, verbose=1, callbacks=[early_stopping])\n",
        "\n",
        "# Make predictions\n",
        "predict_lstm = model_lstm.predict(X)\n",
        "\n",
        "# Inverse transform the predictions\n",
        "predictions = scaler.inverse_transform(predict_lstm)\n",
        "\n",
        "# Print the predictions\n",
        "print(\"Time series predictions:\")\n",
        "print(predictions)\n",
        "\n",
        "# Optionally, to forecast the next values\n",
        "def forecast_next_values(model, data, look_back, num_symbols):\n",
        "    last_sequence = data[-look_back:]\n",
        "    last_sequence = np.reshape(last_sequence, (1, look_back, 1))\n",
        "    next_values_scaled = model.predict(last_sequence)\n",
        "    next_values = scaler.inverse_transform(next_values_scaled)\n",
        "    return next_values\n",
        "\n",
        "next_values = forecast_next_values(model_lstm, data, look_back, num_symbols=2)\n",
        "print(\"Next values forecast:\")\n",
        "print(next_values)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOEUbrZ4XdiC",
        "outputId": "f9533148-34c2-4195-cc38-6c2dd839ead8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "9/9 [==============================] - 2s 5ms/step - loss: 0.4551\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.3819\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.3204\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.2682\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.2213\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 8ms/step - loss: 0.1868\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 12ms/step - loss: 0.1623\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1541\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1499\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1498\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1504\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1466\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1471\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1434\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1431\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1392\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1374\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1388\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.1346\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1328\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1301\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1276\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1240\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.1226\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1177\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1143\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1087\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1052\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0976\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0894\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0797\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0688\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0563\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 0.0436\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0320\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0259\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0206\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0210\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0193\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0191\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.0188\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0182\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0184\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0183\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0188\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0182\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0175\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 10ms/step - loss: 0.0176\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 9ms/step - loss: 0.0174\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 5ms/step - loss: 0.0185\n",
            "1/1 [==============================] - 1s 745ms/step\n",
            "Time series predictions:\n",
            "[[5.6426034  0.6974749 ]\n",
            " [0.68838596 5.5220594 ]\n",
            " [5.1631765  0.9248339 ]\n",
            " [1.6367625  4.8685884 ]\n",
            " [4.482146   1.388758  ]\n",
            " [1.5863967  4.586562  ]\n",
            " [5.7606773  1.0346044 ]\n",
            " [0.7705901  5.4982343 ]\n",
            " [5.279786   0.83728176]]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Next values forecast:\n",
            "[[5.795678   0.68812484]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UcD9LkHRn4t-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}